<!DOCTYPE html> <html lang="en"> <head> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>publications | Salva Rühling Cachay</title> <meta name="author" content="Salva Rühling Cachay"/> <meta name="description" content="(&#x2A) denotes equal contribution"/> <meta name="keywords" content="Salva Rühling Cachay, machine learning, AI, artificial intelligence, deep learning, climate, weather, generative modeling"/> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"/> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="none" id="highlight_theme_light"/> <link rel="shortcut icon" href="/assets/img/favicon.ico"/> <link rel="stylesheet" href="/assets/css/main.css"> <link rel="canonical" href="https://salvarc.github.io/publications/"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark"/> <script src="/assets/js/theme.js"></script> <script src="/assets/js/dark_mode.js"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-bolder" href="https://salvarc.github.io/">Salva Rühling Cachay</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about</a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv</a> </li> <li class="nav-item active"> <a class="nav-link" href="/publications/">publications<span class="sr-only">(current)</span></a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">repositories</a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">blog</a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title">publications</h1> <p class="post-description">(*) denotes equal contribution</p> </header> <article> <div class="publications"> <h2 class="year">2025</h2> <ol class="bibliography"><li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">NeurIPS</abbr></div> <div id="cachay2025erdm" class="col-sm-9"> <div class="title"><a href="https://arxiv.org/abs/2506.20024" target="_blank" rel="noopener noreferrer">Elucidated Rolling Diffusion Models for Probabilistic Weather Forecasting</a></div> <div class="author"> <em>Salva Rühling Cachay</em>, <a href="https://scholar.google.com/citations?user=-_EKVQ0AAAAJ&amp;hl=en" target="_blank" rel="noopener noreferrer">Miika Aittala</a>, <a href="https://karstenkreis.github.io/" target="_blank" rel="noopener noreferrer">Karsten Kreis</a>, <a href="https://www.noahbrenowitz.com/" target="_blank" rel="noopener noreferrer">Noah Brenowitz</a>, <a href="https://scholar.google.com/citations?user=p9-nlRIAAAAJ&amp;hl=en" target="_blank" rel="noopener noreferrer">Arash Vahdat</a>, <a href="https://scholar.google.com/citations?user=pjcBeJYAAAAJ&amp;hl=en" target="_blank" rel="noopener noreferrer">Morteza Mardani</a>, and <a href="https://roseyu.com/" target="_blank" rel="noopener noreferrer">Rose Yu</a> </div> <div class="periodical"> <em>In Advances in Neural Information Processing Systems, 2025.</em> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a> <a class="bibtex btn btn-sm z-depth-0" role="button">BibTex</a> <a href="https://arxiv.org/abs/2506.20024" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a> <a href="https://github.com/salvaRC/erdm" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Code</a> </div> <div class="abstract hidden"> <p>Diffusion models are a powerful tool for probabilistic forecasting, yet most applications in high-dimensional chaotic systems predict future snapshots one-by-one. This common approach struggles to model complex temporal dependencies and fails to explicitly account for the progressive growth of uncertainty inherent to such systems. While rolling diffusion frameworks, which apply increasing noise to forecasts at longer lead times, have been proposed to address this, their integration with state-of-the-art, high-fidelity diffusion techniques remains a significant challenge. We tackle this problem by introducing Elucidated Rolling Diffusion Models (ERDM), the first framework to successfully unify a rolling forecast structure with the principled, performant design of Elucidated Diffusion Models (EDM). To do this, we adapt the core EDM components-its noise schedule, network preconditioning, and Heun sampler-to the rolling forecast setting. The success of this integration is driven by three key contributions: (i) a novel loss weighting scheme that focuses model capacity on the mid-range forecast horizons where determinism gives way to stochasticity; (ii) an efficient initialization strategy using a pre-trained EDM for the initial window; and (iii) a bespoke hybrid sequence architecture for robust spatiotemporal feature extraction under progressive denoising. On 2D Navier-Stokes simulations and ERA5 global weather forecasting at 1.5^∘resolution, ERDM consistently outperforms key diffusion-based baselines, including conditional autoregressive EDM. ERDM offers a flexible and powerful general framework for tackling diffusion-based sequence generation problems where modeling escalating uncertainty is paramount.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">cachay2025erdm</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Elucidated Rolling Diffusion Models for Probabilistic Weather Forecasting}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{R{\"u}hling Cachay, Salva and Aittala, Miika and Kreis, Karsten and Brenowitz, Noah and Vahdat, Arash and Mardani, Morteza and Yu, Rose}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Advances in Neural Information Processing Systems}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2025}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li></ol> <h2 class="year">2024</h2> <ol class="bibliography"><li> <div class="row"> <div class="col-sm-2 abbr"> <abbr class="badge">NeurIPS</abbr><span class="award badge">Spotlight</span> </div> <div id="cachay2024probemulation" class="col-sm-9"> <div class="title"><a href="https://arxiv.org/abs/2406.14798" target="_blank" rel="noopener noreferrer">Probabilistic Emulation of a Global Climate Model with Spherical DYffusion</a></div> <div class="author"> <em>Salva Rühling Cachay</em>, <a href="https://scholar.google.com/citations?user=t2tJH5EAAAAJ" target="_blank" rel="noopener noreferrer">Brian Henn</a>, <a href="https://oliverwm1.github.io/" target="_blank" rel="noopener noreferrer">Oliver Watt-Meyer</a>, <a href="https://atmos.washington.edu/~breth/" target="_blank" rel="noopener noreferrer">Christopher S. Bretherton</a>, and <a href="https://roseyu.com/" target="_blank" rel="noopener noreferrer">Rose Yu</a> </div> <div class="periodical"> <em>In Advances in Neural Information Processing Systems, 2024.</em> </div> <span class="honor"> Spotlight Presentation; Best Paper Award at ICML ML4ESM workshop 2024 </span> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a> <a class="bibtex btn btn-sm z-depth-0" role="button">BibTex</a> <a href="https://arxiv.org/abs/2406.14798" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a> <a href="https://github.com/Rose-STL-Lab/spherical-dyffusion" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Code</a> <a href="/assets/pdf/poster/spherical-dyffusion.pdf" class="btn btn-sm z-depth-0" role="button">Poster</a> <a href="https://docs.google.com/presentation/d/1ol_EOEyKTJb5-KzS-WtF1tsjF-SJSdQA4RRxzqapiJU" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Slides</a> <a href="https://today.ucsd.edu/story/accelerating-climate-modeling-with-generative-ai" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Media</a> </div> <div class="abstract hidden"> <p>Data-driven deep learning models are transforming global weather forecasting. It is an open question if this success can extend to climate modeling, where the complexity of the data and long inference rollouts pose significant challenges. Here, we present the first conditional generative model that produces accurate and physically consistent global climate ensemble simulations by emulating a coarse version of the United States’ primary operational global forecast model, FV3GFS. Our model integrates the dynamics-informed diffusion framework (DYffusion) with the Spherical Fourier Neural Operator (SFNO) architecture, enabling stable 100-year simulations at 6-hourly timesteps while maintaining low computational overhead compared to single-step deterministic baselines. The model achieves near gold-standard performance for climate model emulation, outperforming existing approaches and demonstrating promising ensemble skill. This work represents a significant advance towards efficient, data-driven climate simulations that can enhance our understanding of the climate system and inform adaptation strategies.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">cachay2024probemulation</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Probabilistic Emulation of a Global Climate Model with {Spherical DYffusion}}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{R{\"u}hling Cachay, Salva and Henn, Brian and Watt-Meyer, Oliver and Bretherton, Christopher S. and Yu, Rose}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Advances in Neural Information Processing Systems}</span><span class="p">,</span>
  <span class="na">media</span> <span class="p">=</span> <span class="s">{https://today.ucsd.edu/story/accelerating-climate-modeling-with-generative-ai}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li></ol> <h2 class="year">2023</h2> <ol class="bibliography"><li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">NeurIPS</abbr></div> <div id="cachay2023dyffusion" class="col-sm-9"> <div class="title"><a href="https://openreview.net/forum?id=WRGldGm5Hz" target="_blank" rel="noopener noreferrer">DYffusion: A Dynamics-informed Diffusion Model for Spatiotemporal Forecasting</a></div> <div class="author"> <em>Salva Rühling Cachay</em>, <a href="https://b-zhao.github.io/" target="_blank" rel="noopener noreferrer">Bo Zhao</a>, <a href="https://haileyjoren.github.io/" target="_blank" rel="noopener noreferrer">Hailey Joren</a>, and <a href="https://roseyu.com/" target="_blank" rel="noopener noreferrer">Rose Yu</a> </div> <div class="periodical"> <em>In Advances in Neural Information Processing Systems, 2023.</em> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a> <a class="bibtex btn btn-sm z-depth-0" role="button">BibTex</a> <a href="https://arxiv.org/abs/2306.01984" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a> <a href="https://salvarc.github.io/blog/2023/dyffusion/" class="btn btn-sm z-depth-0" role="button">Blog</a> <a href="https://github.com/Rose-STL-Lab/dyffusion" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Code</a> <a href="/assets/pdf/poster/dyffusion.pdf" class="btn btn-sm z-depth-0" role="button">Poster</a> <a href="https://docs.google.com/presentation/d/e/2PACX-1vQqDOEW5CQWIafaTShAGzAfcbgvAH6t5YPUqTZTPIzToWDfFX776Xtz4Ly31b9654H5uA8dDJGve6aW/pub?start=false&amp;loop=false&amp;delayms=15000&amp;slide=id.p" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Slides</a> </div> <div class="abstract hidden"> <p>While diffusion models can successfully generate data and make predictions, they are predominantly designed for static images. We propose an approach for efficiently training diffusion models for probabilistic spatiotemporal forecasting, where generating stable and accurate rollout forecasts remains challenging, Our method, DYffusion, leverages the temporal dynamics in the data, directly coupling it with the diffusion steps in the model. We train a stochastic, time-conditioned interpolator and a forecaster network that mimic the forward and reverse processes of standard diffusion models, respectively. DYffusion naturally facilitates multi-step and long-range forecasting, allowing for highly flexible, continuous-time sampling trajectories and the ability to trade-off performance with accelerated sampling at inference time. In addition, the dynamics-informed diffusion process in DYffusion imposes a strong inductive bias and significantly improves computational efficiency compared to traditional Gaussian noise-based diffusion models. Our approach performs competitively on probabilistic forecasting of complex dynamics in sea surface temperatures, Navier-Stokes flows, and spring mesh systems.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">cachay2023dyffusion</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{{DYffusion:} A Dynamics-informed Diffusion Model for Spatiotemporal Forecasting}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{R{\"u}hling Cachay, Salva and Zhao, Bo and Joren, Hailey and Yu, Rose}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Advances in Neural Information Processing Systems}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://openreview.net/forum?id=WRGldGm5Hz}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li></ol> <h2 class="year">2021</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">NeurIPS</abbr></div> <div id="cachay2021climart" class="col-sm-9"> <div class="title"><a href="https://openreview.net/forum?id=FZBtIpEAb5J" target="_blank" rel="noopener noreferrer">ClimART: A Benchmark Dataset for Emulating Atmospheric Radiative Transfer in Weather and Climate Models</a></div> <div class="author"> <em>Salva Rühling Cachay</em>*, <a href="https://scholar.google.com/citations?user=IZUbyQkAAAAJ&amp;hl=en" target="_blank" rel="noopener noreferrer">Venkatesh Ramesh*</a>*, <a href="https://scholar.google.com/citations?user=OKehnWoAAAAJ&amp;hl=en" target="_blank" rel="noopener noreferrer">Jason N. S. Cole</a>, <a href="https://www.researchgate.net/profile/Howard-Barker" target="_blank" rel="noopener noreferrer">Howard Barker</a>, and <a href="http://www.davidrolnick.com/" target="_blank" rel="noopener noreferrer">David Rolnick</a> </div> <div class="periodical"> <em>In Advances in Neural Information Processing Systems Datasets and Benchmarks Track, 2021.</em> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a> <a class="bibtex btn btn-sm z-depth-0" role="button">BibTex</a> <a href="https://arxiv.org/abs/2111.14671" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a> <a href="https://github.com/RolnickLab/climart" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Code</a> <a href="/assets/pdf/poster/climart.png" class="btn btn-sm z-depth-0" role="button">Poster</a> <a href="/assets/pdf/slides/ClimART.pdf" class="btn btn-sm z-depth-0" role="button">Slides</a> </div> <div class="abstract hidden"> <p>Numerical simulations of Earth’s weather and climate require substantial amounts of computation. This has led to a growing interest in replacing subroutines that explicitly compute physical processes with approximate machine learning (ML) methods that are fast at inference time. Within weather and climate models, atmospheric radiative transfer (RT) calculations are especially expensive. This has made them a popular target for neural network-based emulators. However, prior work is hard to compare due to the lack of a comprehensive dataset and standardized best practices for ML benchmarking. To fill this gap, we build a large dataset, ClimART, with more than \emph10 million samples from present, pre-industrial, and future climate conditions, based on the Canadian Earth System Model. ClimART poses several methodological challenges for the ML community, such as multiple out-of-distribution test sets, underlying domain physics, and a trade-off between accuracy and inference speed. We also present several novel baselines that indicate shortcomings of datasets and network architectures used in prior work.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">cachay2021climart</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{{ClimART}: A Benchmark Dataset for Emulating Atmospheric Radiative Transfer in Weather and Climate Models}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{R{\"u}hling Cachay*, Salva and Ramesh*, Venkatesh and Cole, Jason N. S. and Barker, Howard and Rolnick, David}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Advances in Neural Information Processing Systems Datasets and Benchmarks Track}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://openreview.net/forum?id=FZBtIpEAb5J}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2021}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">NeurIPS</abbr></div> <div id="cachay2021endtoend" class="col-sm-9"> <div class="title"><a href="https://arxiv.org/abs/2107.02233" target="_blank" rel="noopener noreferrer">End-to-End Weak Supervision</a></div> <div class="author"> <em>Salva Rühling Cachay</em>, <a href="https://benbo.github.io/" target="_blank" rel="noopener noreferrer">Benedikt Boecking</a>, and <a href="https://www.ri.cmu.edu/ri-faculty/artur-w-dubrawski/" target="_blank" rel="noopener noreferrer">Artur Dubrawski</a> </div> <div class="periodical"> <em>In Advances in Neural Information Processing Systems, 2021.</em> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a> <a class="bibtex btn btn-sm z-depth-0" role="button">BibTex</a> <a href="https://arxiv.org/abs/2107.02233" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a> <a href="https://github.com/autonlab/weasel" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Code</a> <a href="/assets/pdf/poster/weasel.pdf" class="btn btn-sm z-depth-0" role="button">Poster</a> <a href="/assets/pdf/slides/WeaSEL.pdf" class="btn btn-sm z-depth-0" role="button">Slides</a> </div> <div class="abstract hidden"> <p>Aggregating multiple sources of weak supervision (WS) can ease the data-labeling bottleneck prevalent in many machine learning applications, by replacing the tedious manual collection of ground truth labels. Current state of the art approaches that do not use any labeled training data, however, require two separate modeling steps: Learning a probabilistic latent variable model based on the WS sources – making assumptions that rarely hold in practice – followed by downstream model training. Importantly, the first step of modeling does not consider the performance of the downstream model. To address these caveats we propose an end-to-end approach for directly learning the downstream model by maximizing its agreement with probabilistic labels generated by reparameterizing previous probabilistic posteriors with a neural network. Our results show improved performance over prior work in terms of end model performance on downstream test sets, as well as in terms of improved robustness to dependencies among weak supervision sources.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">cachay2021endtoend</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{End-to-End Weak Supervision}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{R{\"u}hling Cachay, Salva and Boecking, Benedikt and Dubrawski, Artur}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Advances in Neural Information Processing Systems}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2021}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">arXiv</abbr></div> <div id="cachay2021world" class="col-sm-9"> <div class="title"><a href="https://arxiv.org/abs/2104.05089" target="_blank" rel="noopener noreferrer">The World as a Graph: Improving El Niño Forecasts with Graph Neural Networks</a></div> <div class="author"> <em>Salva Rühling Cachay</em>, <a href="https://www.ri.cmu.edu/ri-people/emma-erickson/" target="_blank" rel="noopener noreferrer">Emma Erickson</a>, <a href="https://arthurfenderbucker.github.io/" target="_blank" rel="noopener noreferrer">Arthur Fender C. Bucker</a>, <a href="https://scholar.google.com/citations?user=jiLNEg0AAAAJ&amp;hl=pl" target="_blank" rel="noopener noreferrer">Ernest Pokropek</a>, <a href="https://potosnakw.github.io/" target="_blank" rel="noopener noreferrer">Willa Potosnak</a>, <a href="https://scholar.google.com/citations?user=smZH_AQAAAAJ&amp;hl=en" target="_blank" rel="noopener noreferrer">Suyash Bire</a>, <a href="https://scholar.google.com/citations?user=32M1HMsAAAAJ" target="_blank" rel="noopener noreferrer">Salomey Osei</a>, and <a href="https://blutjens.github.io/" target="_blank" rel="noopener noreferrer">Björn Lütjens</a> </div> <div class="periodical"> <em>arXiv:2310.14189, 2021.</em> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a> <a class="bibtex btn btn-sm z-depth-0" role="button">BibTex</a> <a href="https://arxiv.org/abs/2104.05089" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a> <a href="https://github.com/salvaRC/graphino" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Code</a> <a href="https://docs.google.com/presentation/d/e/2PACX-1vTt9E0ltCxATjL_zanekINnHttOr68dPypVxs7GZeq8tX-O4BYbY0sMJXZ6UEuLXwdW_n7oQTM8I23g/pub?start=false&amp;loop=false&amp;delayms=3000" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Slides</a> <a href="https://ai4edatasetspublicassets.blob.core.windows.net/grantee-profiles/Salva%20Ruhling%20Cachay_EMEA_Climate_AI4E%20Grantee%20Profile_Final.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Media</a> </div> <div class="abstract hidden"> <p>Deep learning-based models have recently outperformed state-of-the-art seasonal forecasting models, such as for predicting El Ni no-Southern Oscillation (ENSO). However, current deep learning models are based on convolutional neural networks which are difficult to interpret and can fail to model large-scale atmospheric patterns. In comparison, graph neural networks (GNNs) are capable of modeling large-scale spatial dependencies and are more interpretable due to the explicit modeling of information flow through edge connections. We propose the first application of graph neural networks to seasonal forecasting. We design a novel graph connectivity learning module that enables our GNN model to learn large-scale spatial interactions jointly with the actual ENSO forecasting task. Our model, \graphino, outperforms state-of-the-art deep learning-based models for forecasts up to six months ahead. Additionally, we show that our model is more interpretable as it learns sensible connectivity structures that correlate with the ENSO anomaly pattern.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">cachay2021world</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{The World as a Graph: Improving El Ni\~no Forecasts with Graph Neural Networks}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{R{\"u}hling Cachay, Salva and Erickson, Emma and Fender C. Bucker, Arthur and Pokropek, Ernest and Potosnak, Willa and Bire, Suyash and Osei, Salomey and Lütjens, Björn}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{arXiv:2310.14189}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2021}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> <abbr class="badge">ICLR Workshop</abbr><span class="award badge">Oral</span> </div> <div id="cachay2021dependency" class="col-sm-9"> <div class="title"><a href="https://arxiv.org/abs/2106.10302" target="_blank" rel="noopener noreferrer">Dependency Structure Misspecification in Multi-Source Weak Supervision Models</a></div> <div class="author"> <em>Salva Rühling Cachay</em>, <a href="https://benbo.github.io/" target="_blank" rel="noopener noreferrer">Benedikt Boecking</a>, and <a href="https://www.ri.cmu.edu/ri-faculty/artur-w-dubrawski/" target="_blank" rel="noopener noreferrer">Artur Dubrawski</a> </div> <div class="periodical"> <em>In ICLR Weakly Supervised Learning workshop and NeurIPS 2020 LatinX in AI workshop , 2021.</em> </div> <span class="honor"> Oral Presentation </span> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a> <a class="bibtex btn btn-sm z-depth-0" role="button">BibTex</a> <a href="https://arxiv.org/abs/2106.10302" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a> <a href="/assets/pdf/poster/ICLR_DP_Misspecification.png" class="btn btn-sm z-depth-0" role="button">Poster</a> <a href="/assets/pdf/slides/ICLR_DP_Misspecification.pdf" class="btn btn-sm z-depth-0" role="button">Slides</a> </div> <div class="abstract hidden"> <p>Data programming (DP) has proven to be an attractive alternative to costly hand-labeling of data. In DP, users encode domain knowledge into \emphlabeling functions (LF), heuristics that label a subset of the data noisily and may have complex dependencies. A label model is then fit to the LFs to produce an estimate of the unknown class label. The effects of label model misspecification on test set performance of a downstream classifier are understudied. This presents a serious awareness gap to practitioners, in particular since the dependency structure among LFs is frequently ignored in field applications of DP. We analyse modeling errors due to structure over-specification. We derive novel theoretical bounds on the modeling error and empirically show that this error can be substantial, even when modeling a seemingly sensible structure.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">cachay2021dependency</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Dependency Structure Misspecification in Multi-Source Weak Supervision Models}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{R{\"u}hling Cachay, Salva and Boecking, Benedikt and Dubrawski, Artur}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{ICLR Weakly Supervised Learning workshop and NeurIPS 2020 LatinX in AI workshop }</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2021}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> </div> </article> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> © Copyright 2025 Salva Rühling Cachay. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="noopener noreferrer">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" target="_blank" rel="noopener noreferrer">al-folio</a> theme. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js"></script> <script defer src="/assets/js/common.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script async src="https://www.googletagmanager.com/gtag/js?id=G-EJL52VZ7F6"></script> <script>function gtag(){window.dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-EJL52VZ7F6");</script> </body> </html>